1.Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?
‘f1_micro’	metrics.f1_score	микро-усредненный
‘f1_macro’	metrics.f1_score	микро-усредненный
‘f1_weighted’	metrics.f1_score	средневзвешенное
F1-оценка: это индекс, используемый для измерения точности модели двоичной классификации в статистике, и он используется для измерения
 точности несбалансированных данных. Он также принимает во внимание точность и отзывчивость модели классификации. F1-оценку можно 
рассматривать как средневзвешенное значение точности и запоминаемости модели. Максимальное значение - 1, минимальное - 0.
В задаче множественной классификации, если надо рассчитать F1-оценку модели, есть два метода расчета, 
а именно микро-F1 и макро-F1. Эти два метода расчета аналогичны методам расчета F1-оценки. в двух классификациях.
Так, в задаче с двумя категориями вычислить микро-F1 = макро-F1 = F1-оценка, микро-F1 и макро-F1 - это два метода 
расчета мультикатегорийной F1-оценки;
MICRO-F1：
Диапазоны：(0, 1)；
Применимая среда: Мульти-категория несбалансирована, если данные крайне несбалансированы, это повлияет на результаты;
Расчет:
 〖Recall〗_mi=(TP_1+TP_2+TP_3)/(TP_1+TP_2+TP_3+FN_1+FN_2+FN_3 )； 〖Precision〗_mi=(TP_1+TP_2+TP_3)/(TP_1+TP_2+TP_3+FP_1+FP_2+FP_3 )
 micro F1score=2 (〖Recall〗_mi  × 〖Precision〗_mi)/(〖Recall〗_mi  + 〖Precision〗_mi )
TPi означает, что истинно положительный класс i-го класса оценивается как положительный класс;
FPi означает, что ложноположительный отрицательный класс i-го класса оценивается как положительный класс;
TNi относится к истинно отрицательному i-й категории, а положительная категория оценивается как отрицательная категория;
FNi означает, что ложноотрицательный результат i-й категории считается отрицательной категорией.

Предположим, теперь есть следующие три результата классификации:
Confusion Matrix	Real1	2	3Predict	1	a	d	g2	b	e	h3	c	f	i
Из этой таблицы мы можем получить:
Для первой категории: FP1 = d + g; TP1 = a; FN1 = b + c; TN1 = e + f + h + i;
Для категории 2: FP2 = b + h; TP2 = e; FN2 = d + f; TN2 = a + c + g + i;
Для категории 3: FP3 = c + f; TP3 = i; FN3 = g + h; TN3 = a + b + d + e;

Для micro-F1 метод расчета mirco сочетает в себе отзывчивость и точность, поэтому:

заmicro-Recall: Скорость отзыва составляет (TP1 + TP2 + TP3) / (TP1 + TP2 + TP3 + FN1 + FN2 + FN3), 
то есть три категории TP и FN складываются вместе в знаменателе, а TP - в числителе. Из анализа приведенной выше формулы мы видим,
 что TP1 + TP2 + TP3 = a + e + i; FN1 + FN2 + FN3 = b + c + d + f + g + h (то есть притяжательные, кроме TP),
 так что мы получаем〖Recall〗_mi=(a+e+i)/(a+e+i+b+c+d+f+g+h)
дляmicro-Precision： Точность составляет (TP1 + TP2 + TP3) / (TP1 + TP2 + TP3 + FP1 + FP2 + FP3), можно получить то же самое,
 TP1 + TP2 + TP3 = a + e + i; FP1 + FP2 + FP3 = d + g + b + h + c + f (т.е. притяжательные, кроме TP), получаем
 
Затем, согласно методу расчета микро F1-score:
 
И для точности моделиAccuracy, Определяется как доля правильно классифицированных образцов во всех выборках. Итак, формула точности
Acc=(a+e+i)/(a+b+c+d+e+f+g+h+i)
означает:
 
Исходя из этого, мы можем сделать вывод: если micro-F1 = 0,5, точность модели Acc = 0,5, Precision и Recall равны 0,5, 
но мы не можем сделать вывод, что модель в основном зависит от предположения Вывод, потому что если три результата классификации следующие:
 Acc=(a+e+i)/(a+b+c+d+e+f+g+h+i)=micro-F1=Precision_mi=Recall_mi=0.5


MACRO-F1：
Диапазоны：(0, 1)；
Применимая среда: Проблема с множественной классификацией, не подверженная дисбалансу данных, легко затрагивается категориями 
с высокой узнаваемостью (высокая отзывчивость, высокая точность);
Метод расчета：
 〖F1-score〗_i=2 (〖Recall〗_i×〖Precision〗_i)/(〖Recall〗_i+〖Precision〗_i )； macro F1score=(〖F1-score〗_1+ 〖F1-score〗_2+〖F1-score〗_3)/3

макро-F1 имеет Два метода расчета，

1. Сначала найдите макрос-Recall и macro-Pecision, а затем найдите макро-F1 из суммы этих двух;
2. Непосредственно усредните F1-балл по трем категориям.

В пакете sklearn используется второй метод.способ Так рассчитывается макро-F1.

Мы также можем проанализировать два метода усреднения. Первый метод не очень чувствителен к распределению ошибок ». 

Аналогичным образом мы анализируем каждую категорию показателей:
Для первой категории: FP1 = d + g; TP1 = a; FN1 = b + c; TN1 = e + f + h + i;
Для категории 2: FP2 = b + h; TP2 = e; FN2 = d + f; TN2 = a + c + g + i;
Для категории 3: FP3 = c + f; TP3 = i; FN3 = g + h; TN3 = a + b + d + e;
 1 ：〖Recall〗_1=〖TP〗_1/(〖TP〗_1+〖FN〗_1 )；〖Precision〗_1=〖TP〗_1/(〖TP〗_1+〖FP〗_1 )；
〖F1-score〗_1=(2〖TP〗_1)/(〖2TP〗_1+〖FP〗_1+〖FN〗_1 ) 2 ：〖Recall〗_2=〖TP〗_2/(〖TP〗_2+〖FN〗_2 )；
〖Precision〗_2=〖TP〗_2/(〖TP〗_2+〖FP〗_2 )；〖F1-score〗_1=(2〖TP〗_1)/(〖2TP〗_1+〖FP〗_1+〖FN〗_1 )
 3 ：〖Recall〗_3=〖TP〗_3/(〖TP〗_3+〖FN〗_3 )；〖Precision〗_3=〖TP〗_3/(〖TP〗_3+〖FP〗_3 )；
〖F1-score〗_1=(2〖TP〗_1)/(〖2TP〗_1+〖FP〗_1+〖FN〗_1 )
Введите указанное выше значение в макрос-F1 и получите:
macro-F1=(〖F1-score〗_1+ 〖F1-score〗_2+〖F1-score〗_3)/3=((2〖TP〗_1)/(〖2TP〗_1+〖FP〗_1+〖FN〗_1 )
+ (2〖TP〗_2)/(〖2TP〗_2+〖FP〗_2+〖FN〗_2 )+(2〖TP〗_3)/(〖2TP〗_3+〖FP〗_3+〖FN〗_3 ))/3=(2a/(2a+b+c+d+g)+ 2e/(2e+b+d+f+h)+2i/(2i+c+f+g+h))/3
Вышеупомянутая формула является формулой макроса F1 
Если значение = 0,5, то полезного заключения сделать нельзя.
WEIGHTED-F1
Помимо микро-F1 и макро-F1, существует также взвешенный-F1, который является результатом умножения F1-балла 
на долю этого типа и последующего сложения. Его также можно рассматривать как вариант макро-F1. . Например: 
 мы можем получить точность, отзывчивость и оценку F1: 
Итак, для взвешенного F1:
weighted-F1=(6×42.1%+10×30.8%+9×66.7%)/(4+6+3+1+2+0+1+2+6)=46.4%
Точно так же мы также можем вычислить взвешенную точность и взвешенную отзыв: 
Фактически, из вышесказанного также видно,weighted-F1Он не равен вычисленному с помощью взвешенной точности
 и взвешенного отзыва.Weighted-F1(Здесь для того, чтобы выразить соответственно заглавными буквами) по той
 же причине относятся к двум методам вычисления макроса. 

2.В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?
CatBoost обладает гибкостью, позволяя задавать индексы категориальных столбцов, чтобы его можно было кодировать как 
кодирование в одно касание с использованием one_hot_max_size (используйте кодирование в одно касание для всех функций
 с числом различных значений, меньшим или равным данному значению параметра).
Если вы ничего не передаете в аргументе cat_features, CatBoost будет обрабатывать все столбцы как числовые переменные.
LightGBM
Как и в CatBoost, LightGBM также может обрабатывать категориальные функции, вводя имена функций. Он не конвертируется 
в одноразовое кодирование и намного быстрее, чем одноразовое кодирование. LGBM использует специальный алгоритм,
 чтобы найти значение разделения категориальных признаков
Перед построением набора данных для LGBM вы должны преобразовать свои категориальные функции в тип int.
 Он не принимает строковые значения, даже если вы передаете его через параметр categoryorical_feature.
XGBoost
В отличие от CatBoost или LGBM, XGBoost не может обрабатывать категориальные функции сам по себе,
 он принимает только числовые значения, подобные случайному лесу. Поэтому перед подачей категориальных данных
 в XGBoost необходимо выполнить различные кодировки, такие как кодирование меток, среднее кодирование или однократное кодирование.